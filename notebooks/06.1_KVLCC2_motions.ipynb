{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KVLCC2 in motions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose\n",
    "This notebook analyzes the first results from roll decay simulations in Motions (without vicsous damping)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methodology\n",
    "Quickly describe assumptions and processing steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load imports.py\n",
    "\"\"\"\n",
    "These is the standard setup for the notebooks.\n",
    "\"\"\"\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from jupyterthemes import jtplot\n",
    "jtplot.style(theme='onedork', context='notebook', ticks=True, grid=False)\n",
    "\n",
    "import pandas as pd\n",
    "pd.options.display.max_rows = 999\n",
    "pd.options.display.max_columns = 999\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "#plt.style.use('paper')\n",
    "\n",
    "#import data\n",
    "import copy\n",
    "from mdldb.run import Run\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from rolldecayestimators.transformers import CutTransformer, LowpassFilterDerivatorTransformer, ScaleFactorTransformer, OffsetTransformer\n",
    "from rolldecayestimators.direct_estimator_cubic import EstimatorQuadraticB, EstimatorCubic\n",
    "from rolldecayestimators.ikeda_estimator import IkedaQuadraticEstimator\n",
    "import rolldecayestimators.equations as equations\n",
    "import rolldecayestimators.lambdas as lambdas\n",
    "from rolldecayestimators.substitute_dynamic_symbols import lambdify\n",
    "import rolldecayestimators.symbols as symbols\n",
    "import sympy as sp\n",
    "\n",
    "from sympy.physics.vector.printing import vpprint, vlatex\n",
    "from IPython.display import display, Math, Latex\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from src.data import database\n",
    "from mdldb import tables\n",
    "import shipflowmotionshelpers.shipflowmotionshelpers as helpers\n",
    "import shipflowmotionshelpers.preprocess as preprocess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from pyscores2.output import OutputFile\n",
    "from rolldecayestimators.ikeda import Ikeda, IkedaR\n",
    "from pyscores2.runScores2 import Calculation\n",
    "from pyscores2.indata import Indata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data from Motions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = [\n",
    "    '../data/external/kvlcc2_rolldecay_0kn',\n",
    "]\n",
    "#file_path_viscous = 'data/Final_use_in_parametric_roll_simulations/m5030_HADR_B100_Q100_rolldecay_10kn_TS.csv'\n",
    "\n",
    "#df = helpers.load_time_series(file_path_no_viscous)  # No vicous damping\n",
    "#df_visc = helpers.load_time_series(file_path_viscous) # Including vicous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parameters = pd.DataFrame()\n",
    "df_parameters =  helpers.load_parameters(file_path=file_paths)\n",
    "#df_parameters.rename(index={'kvlcc2_rolldecay_0kn':'inviscid'}, inplace=True)\n",
    "df_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series = helpers.load_time_series(df_parameters=df_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = time_series['kvlcc2_rolldecay_0kn']\n",
    "X = df\n",
    "fig,ax=plt.subplots()\n",
    "X.plot(y='phi', ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load MDL results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = database.get_db()\n",
    "\n",
    "sql = \"\"\"\n",
    "SELECT * from run\n",
    "INNER JOIN loading_conditions\n",
    "ON (run.loading_condition_id = loading_conditions.id)\n",
    "INNER JOIN models\n",
    "ON (run.model_number = models.model_number)\n",
    "INNER JOIN ships\n",
    "ON (run.ship_name = ships.name)\n",
    "WHERE run.model_number='M5057-01-A' and run.test_type='roll decay' and run.project_number=40178362;\n",
    "\"\"\"\n",
    "df_rolldecays = pd.read_sql(sql=sql, con=db.engine)\n",
    "df_rolldecays['rho']=1000\n",
    "df_rolldecays['g']=9.81\n",
    "df_rolldecays=df_rolldecays.loc[:,~df_rolldecays.columns.duplicated()]\n",
    "df_rolldecays.set_index('id', inplace=True)\n",
    "\n",
    "df_rolldecays['ship_speed'].fillna(0, inplace=True)\n",
    "df_rolldecays=df_rolldecays.loc[[21338,21340,]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_paths={\n",
    "    21338 : {\n",
    "        'scores_indata_path':'../models/KVLCC2_speed.IN',\n",
    "        'scores_outdata_path':'../data/interim/KVLCC2_speed.out',\n",
    "        'roll_decay_model':'../models/KVLCC2_0_speed.pkl',\n",
    "        'motions_file_paths': ['kvlcc2_rolldecay_0kn'],\n",
    "            \n",
    "            },\n",
    "    21340 : {\n",
    "        'scores_indata_path':'../models/KVLCC2_speed.IN',\n",
    "        'scores_outdata_path':'../data/interim/KVLCC2_speed.out',\n",
    "        'roll_decay_model':'../models/KVLCC2_speed.pkl',\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g=9.81\n",
    "rho=1000\n",
    "\n",
    "def get_ikeda(indata_file_path:str, output_file_path:str, mdl_meta_data:pd.Series, omega0:float, phi_a=np.deg2rad(10)):\n",
    "\n",
    "    scale_factor = mdl_meta_data.scale_factor\n",
    "    \n",
    "    ## Load ScoresII results\n",
    "    indata = Indata()\n",
    "    indata.open(indataPath=indata_file_path)\n",
    "    output_file = OutputFile(filePath=output_file_path)\n",
    "        \n",
    "    ## Run Ikeda\n",
    "    w = omega0\n",
    "    V = mdl_meta_data.ship_speed*1.852/3.6/np.sqrt(scale_factor)\n",
    "    \n",
    "    if not mdl_meta_data.BKL:\n",
    "        BKL=0\n",
    "    else:\n",
    "        BKL=mdl_meta_data.BKL/scale_factor\n",
    "    \n",
    "    if not mdl_meta_data.BKB:\n",
    "        BKB = 0\n",
    "    else:\n",
    "        BKB=mdl_meta_data.BKB/scale_factor\n",
    "       \n",
    "    BKL_ = BKL*np.ones(len(phi_a))\n",
    "    BKB_ = BKB*np.ones(len(phi_a))\n",
    "    \n",
    "    ikeda = Ikeda.load_scoresII(V=V, w=w, fi_a=phi_a, indata=indata, output_file=output_file, \n",
    "                                scale_factor=scale_factor, BKL=BKL_, BKB=BKB_)\n",
    "    \n",
    "    R = 0.15*mdl_meta_data.beam/scale_factor  # Just guessing...\n",
    "    ikeda.R = R\n",
    "    \n",
    "    #ikeda = IkedaR.load_scoresII(V=V, w=w, fi_a=phi_a, indata=indata, output_file=output_file, \n",
    "    #                            scale_factor=scale_factor, BKL=BKL_, BKB=BKB_)\n",
    "        \n",
    "    return ikeda\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ikeda(ikeda):\n",
    "\n",
    "    output = pd.DataFrame()\n",
    "    output['B_44_hat']   = ikeda.calculate_B44()\n",
    "    output['B_W0_hat']   = float(ikeda.calculate_B_W0())\n",
    "    output['B_W_hat']    = float(ikeda.calculate_B_W())\n",
    "    output['B_F_hat']    = ikeda.calculate_B_F()\n",
    "    output['B_E_hat']    = ikeda.calculate_B_E()\n",
    "    output['B_BK_hat']   = ikeda.calculate_B_BK()\n",
    "    output['B_L_hat']    = float(ikeda.calculate_B_L())\n",
    "    output['Bw_div_Bw0'] = float(ikeda.calculate_Bw_div_Bw0())\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_estimator_variation(estimator, results, meta_data):\n",
    "\n",
    "    X_amplitudes=estimator.X_pred_amplitudes.copy()\n",
    "    phi_a=X_amplitudes['phi_a']\n",
    "    B_e = lambdas.B_e_lambda_cubic(B_1=results['B_1'], B_2=results['B_2'], B_3=results['B_3'], \n",
    "                                   omega0=results['omega0'], phi_a=phi_a)\n",
    "    B_e_hat = lambdas.B_hat_lambda(B=B_e, Disp=meta_data['Volume'], beam=meta_data['beam'], g=meta_data['g'], rho=meta_data['rho'])\n",
    "    X_amplitudes['B_e'] = B_e\n",
    "    X_amplitudes['B_e_hat'] = B_e_hat\n",
    "    X_amplitudes['B_e'] = X_amplitudes['B_e'].astype(float)\n",
    "    X_amplitudes['B_e_hat'] = X_amplitudes['B_e_hat'].astype(float)   \n",
    "    \n",
    "    return X_amplitudes\n",
    "\n",
    "def get_data_variation(estimator, results, meta_data):\n",
    "    \n",
    "    X_amplitudes=estimator.X_amplitudes\n",
    "    omega0=estimator.omega0\n",
    "    A_44=results['A_44']\n",
    "    X_amplitudes['B']=X_amplitudes['B_n']*2*omega0*A_44/2\n",
    "    X_amplitudes['B_hat'] = lambdas.B_hat_lambda(B=X_amplitudes['B'], Disp=meta_data['Volume'], beam=meta_data['beam'], g=meta_data['g'], rho=meta_data['rho'])\n",
    "    return X_amplitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = OrderedDict()\n",
    "\n",
    "for run_id, run in run_paths.items():\n",
    "    \n",
    "    mdl_meta_data = df_rolldecays.loc[run_id]\n",
    "    runs[run_id] = new_run = {\n",
    "        'motions':{},\n",
    "    }\n",
    "    \n",
    "    ## MDL:\n",
    "    model_mdl = joblib.load(run['roll_decay_model'])\n",
    "    estimator_mdl = model_mdl['estimator']\n",
    "    estimator_mdl.calculate_amplitudes_and_damping()\n",
    "    new_run['model_mdl']=model_mdl\n",
    "    new_run['estimator_mdl']=estimator_mdl\n",
    "    \n",
    "    scale_factor = mdl_meta_data.scale_factor\n",
    "    new_run['meta_data'] = meta_data={\n",
    "            'Volume':mdl_meta_data.Volume/(scale_factor**3),\n",
    "            'GM':mdl_meta_data.gm/scale_factor,\n",
    "            'rho':mdl_meta_data.rho,\n",
    "            'g':mdl_meta_data.g,\n",
    "            'beam':mdl_meta_data.beam/scale_factor,\n",
    "        }\n",
    "    \n",
    "    new_run['results'] = results = estimator_mdl.result_for_database(meta_data=meta_data)\n",
    "    \n",
    "    # Prediction\n",
    "    new_run['df_model'] = get_estimator_variation(estimator = estimator_mdl, results=results, meta_data=meta_data)\n",
    "    \n",
    "    # Model tests\n",
    "    new_run['df'] = get_data_variation(estimator = estimator_mdl, results=results, meta_data=meta_data)\n",
    "    phi_a = new_run['df']['phi_a']\n",
    "    \n",
    "    ## Motions\n",
    "    for motions_file_path in run.get('motions_file_paths',[]):\n",
    "        motion_file = new_run['motions'][motions_file_path] = {}\n",
    "        \n",
    "        motion_file['parameters'] = parameters = df_parameters.loc[motions_file_path]\n",
    "        \n",
    "        motion_file['X'] = X = time_series[motions_file_path]\n",
    "        \n",
    "                \n",
    "        motion_file['model'] = model = EstimatorCubic(p0=estimator_mdl.parameters)\n",
    "        model.fit(X=X)\n",
    "        assert model.score() > 0.99\n",
    "        \n",
    "        motion_file['meta_data'] = meta_data ={\n",
    "            'Volume':parameters.V,\n",
    "            'GM':mdl_meta_data.gm/mdl_meta_data.scale_factor,\n",
    "            'rho':parameters.dens,\n",
    "            'g':parameters.gravi,\n",
    "            'beam':parameters.B,\n",
    "        }\n",
    "    \n",
    "        results = model.result_for_database(meta_data=meta_data)\n",
    "        motion_file['results'] = results\n",
    "        model.calculate_amplitudes_and_damping()\n",
    "        \n",
    "        # Prediction\n",
    "        motion_file['df_model'] = get_estimator_variation(estimator = model, results = results, meta_data=meta_data)\n",
    "                \n",
    "        # Simulation\n",
    "        motion_file['df'] = get_data_variation(estimator = model, results = results, meta_data=meta_data)\n",
    "        \n",
    "                \n",
    "    ## Ikeda\n",
    "    new_run['ikeda'] = ikeda =  {}\n",
    "    omega0=new_run['results']['omega0']     \n",
    "    ikeda['estimator'] = ikeda_estimator = get_ikeda(indata_file_path=run['scores_indata_path'], output_file_path=run['scores_outdata_path'], mdl_meta_data=mdl_meta_data, omega0=omega0, phi_a=phi_a)\n",
    "    ikeda['df'] = results = calculate_ikeda(ikeda = ikeda_estimator)\n",
    "    results['phi_a'] = phi_a\n",
    "    results.set_index('phi_a', inplace=True)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id=21338\n",
    "run = runs[run_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='damping'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ikeda = run['ikeda']['df']\n",
    "\n",
    "fig,ax=plt.subplots()\n",
    "interesting_ = ['B_L_hat','B_W_hat','B_F_hat','B_E_hat',]\n",
    "df_ikeda.plot.area(y=interesting_, ax=ax)\n",
    "\n",
    "## Model test\n",
    "run['df'].plot(x='phi_a', y='B_hat', style='b.', label='Model test', ax=ax)\n",
    "run['df_model'].plot(x='phi_a', y='B_e_hat', style='-', label='Cubic model test', ax=ax)\n",
    "\n",
    "## Motions\n",
    "motion_file = run['motions']['kvlcc2_rolldecay_0kn']\n",
    "motion_file['df'].plot(x='phi_a', y='B_hat', style='k.', label='Motions inviscid', ax=ax)\n",
    "motion_file['df_model'].plot(x='phi_a', y='B_e_hat', style='-', label='Cubic model Motions', ax=ax)\n",
    "ax.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
